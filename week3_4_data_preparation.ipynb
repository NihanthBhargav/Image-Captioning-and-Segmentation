{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e813b6",
   "metadata": {},
   "source": [
    "## Image Captioning And Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d1967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bollejayanthsriteja\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading captions...\n",
      "Loaded captions for 8092 images\n",
      "Cleaned captions saved to ./processed\\cleaned_captions.csv\n",
      "Tokenizer saved. Vocab size: 8832\n",
      "Max caption length: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 8091/8091 [35:58<00:00,  3.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features saved to ./features\n",
      "Metadata saved to ./processed\\metadata.json\n",
      "\n",
      "Data preparation completed. Ready for Week 5-6 model training.\n",
      "Processed image list saved to ./processed\\processed_images.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Week 3-4 Data Preparation for Image Captioning (Flickr8k)\n",
    "# Notebook-Friendly Version (no CLI args)\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set Your Paths Here \n",
    "images_dir = \"./images\"\n",
    "captions_file = \"./captions/Flickr8k.token.txt\"\n",
    "features_dir = \"./features\"\n",
    "output_dir = \"./processed\"\n",
    "sample = 0\n",
    "\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load Raw Captions\n",
    "\n",
    "def load_raw_captions(captions_file):\n",
    "    descriptions = defaultdict(list)\n",
    "    with open(captions_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            img_cap, caption = line.strip().split('\\t')\n",
    "            img_id = img_cap.split('#')[0]\n",
    "            descriptions[img_id].append(caption)\n",
    "    return descriptions\n",
    "\n",
    "print(\"Loading captions...\")\n",
    "descriptions = load_raw_captions(captions_file)\n",
    "print(f\"Loaded captions for {len(descriptions)} images\")\n",
    "\n",
    "if sample > 0:\n",
    "    keys = sorted(list(descriptions.keys()))[:sample]\n",
    "    descriptions = {k: descriptions[k] for k in keys}\n",
    "    print(f\"Using sample of {len(descriptions)} images\")\n",
    "\n",
    "# Clean Captions \n",
    "\n",
    "def clean_caption_text(caption):\n",
    "    caption = caption.lower()\n",
    "    caption = re.sub(r\"[^a-z0-9\\s]\", '', caption)\n",
    "    caption = re.sub(r\"\\s+\", ' ', caption).strip()\n",
    "    return '<start> ' + caption + ' <end>'\n",
    "\n",
    "cleaned = {img: [clean_caption_text(c) for c in caps] for img, caps in descriptions.items()}\n",
    "\n",
    "# Save cleaned captions to CSV\n",
    "rows = [(img, c) for img, caps in cleaned.items() for c in caps]\n",
    "df = pd.DataFrame(rows, columns=['image', 'caption'])\n",
    "cleaned_csv_path = os.path.join(output_dir, 'cleaned_captions.csv')\n",
    "df.to_csv(cleaned_csv_path, index=False)\n",
    "print(f\"Cleaned captions saved to {cleaned_csv_path}\")\n",
    "\n",
    "# Tokenizer \n",
    "all_captions = [c for caps in cleaned.values() for c in caps]\n",
    "tokenizer = Tokenizer(oov_token='<unk>', filters='')\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "tokenizer_path = os.path.join(output_dir, 'tokenizer.pkl')\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved. Vocab size: {vocab_size}\")\n",
    "\n",
    "# Max Caption Length \n",
    "max_length = max(len(c.split()) for c in all_captions)\n",
    "print(f\"Max caption length: {max_length}\")\n",
    "\n",
    "# Extract Image Features \n",
    "model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def extract_and_save_features(images_dir, features_dir, image_list=None):\n",
    "    if image_list is None:\n",
    "        files = [f for f in os.listdir(images_dir) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    else:\n",
    "        files = [f for f in image_list if os.path.exists(os.path.join(images_dir, f))]\n",
    "    files.sort()\n",
    "    if sample > 0:\n",
    "        files = files[:sample]\n",
    "    for fname in tqdm(files, desc='Extracting features'):\n",
    "        img_path = os.path.join(images_dir, fname)\n",
    "        try:\n",
    "            img = keras_image.load_img(img_path, target_size=(299, 299))\n",
    "            x = keras_image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            feature = model.predict(x, verbose=0)\n",
    "            feature_path = os.path.join(features_dir, fname + '.npy')\n",
    "            np.save(feature_path, feature)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "extract_and_save_features(images_dir, features_dir, list(cleaned.keys()))\n",
    "print(f\"Image features saved to {features_dir}\")\n",
    "\n",
    "# Save Metadata\n",
    "metadata = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'max_length': max_length,\n",
    "    'num_images': len(cleaned)\n",
    "}\n",
    "meta_path = os.path.join(output_dir, 'metadata.json')\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Metadata saved to {meta_path}\")\n",
    "\n",
    "print(\"\\nData preparation completed. Ready for Week 5-6 model training.\")\n",
    "\n",
    "processed_images = list(cleaned.keys())\n",
    "pkl_path = os.path.join(output_dir, 'processed_images.pkl')\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump(processed_images, f)\n",
    "\n",
    "print(f\"Processed image list saved to {pkl_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
